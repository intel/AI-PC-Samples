{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf18a6fe-17e3-4a21-8bf7-7e77f2ec7e91",
   "metadata": {},
   "source": [
    "# Genre-Driven Storytelling from Images using PyTorch XPU backend\n",
    "## Overview\n",
    "This sample explores the generation of creative, genre-specific stories from images, specifically optimized for Intel hardware using the PyTorch XPU backend. \n",
    "\n",
    "## Workflow\n",
    "It takes an image and a user-defined genre (e.g., fantasy, horror, romance, sci-fi) as input and leverages a Vision Language Model (VLM) to craft engaging narratives that are visually inspired and thematically aligned with the chosen genre.\n",
    "\n",
    "<img width=\"600\" alt=\"image\" src=\"./assets/story-generation.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f628be0-dcd7-4631-b9e5-ee2ff35fff92",
   "metadata": {},
   "source": [
    "## Import Necessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb02b8bc-4c93-4f83-b576-994fb798662a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Qwen2_5_VLForConditionalGeneration, AutoTokenizer, AutoProcessor\n",
    "import torch\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Image as IPImage \n",
    "from PIL import Image as PILImage \n",
    "from qwen_vl_utils import process_vision_info\n",
    "import io\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3c36823-14d9-4cab-9d38-afb5209b7fa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b4a0b421cea40d292a4430a5695c9c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead6b844-650f-45cd-be85-3777ca676ca9",
   "metadata": {},
   "source": [
    "## Story Generation Module\n",
    "\n",
    "Using Qwen VL Model, users could generate a creative genre-specific story with minimal prompt changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6e40b8f-d408-485c-af37-9ea173df9df1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def story_generation(image, genre):\n",
    "    \"\"\"\n",
    "        Generates a creative story using Qwen 2.5 VL 3B Instruct model\n",
    "        Args:\n",
    "            image(PIL image): User uploaded image\n",
    "            genre(str): User selected genre(eg. Fantasy, Horror, Sci-fi, etc.)\n",
    "        Returns: \n",
    "            story(str): Model generated story\n",
    "    \"\"\"\n",
    "    try:\n",
    "        model_id = \"Qwen/Qwen2.5-VL-3B-Instruct\"\n",
    "        try:\n",
    "            min_pixels = 256*28*28\n",
    "            max_pixels = 1280*28*28\n",
    "            processor = AutoProcessor.from_pretrained(model_id,\n",
    "                                                      local_files_only=True,\n",
    "                                                      use_fast=True,\n",
    "                                                      min_pixels=min_pixels, \n",
    "                                                      max_pixels=max_pixels)\n",
    "            model = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n",
    "                model_id,\n",
    "                local_files_only=True,\n",
    "                torch_dtype=torch.bfloat16,\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Model '{model_id}' is not available locally. Please download it first using the CLI command( refer README)\")\n",
    "            raise\n",
    "        device = \"xpu\" if torch.xpu.is_available() else \"cpu\"\n",
    "        model = model.to(device)\n",
    "        model.eval()\n",
    "        compiled_model = torch.compile(model)\n",
    "            \n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"image\",\n",
    "                        \"image\": image,\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        # \"text\": prompt,\n",
    "                        \"text\": f\"Generate a creative {genre} story inspired by this image. Focus on the characters (if any are visible, describe them briefly), the atmosphere of the scene, and the potential narrative that could unfold. Craft an engaging plot and ensure the story conveys a suitable moral.\"                    \n",
    "                    },\n",
    "                ],\n",
    "            }\n",
    "        ]\n",
    "        # Preparation for inference\n",
    "        text = processor.apply_chat_template(\n",
    "            messages, \n",
    "            tokenize=False, \n",
    "            add_generation_prompt=True\n",
    "        )\n",
    "        image_inputs, video_inputs = process_vision_info(messages)\n",
    "        inputs = processor(text=[text], \n",
    "                           images=[image], \n",
    "                           padding=True, \n",
    "                           return_tensors=\"pt\")\n",
    "        inputs = inputs.to(\"xpu\")\n",
    "    \n",
    "        torch.xpu.empty_cache()\n",
    "        # Generation of the output\n",
    "        with torch.no_grad():\n",
    "            generated_ids = compiled_model.generate(**inputs, \n",
    "                                           temperature=0.9,\n",
    "                                           top_p=0.99,\n",
    "                                           top_k=40,\n",
    "                                           do_sample=True,\n",
    "                                           max_new_tokens=1024)\n",
    "            generated_ids_trimmed = [\n",
    "                out_ids[len(in_ids) :] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n",
    "            ]\n",
    "            output_text = processor.batch_decode(\n",
    "                generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    "            )\n",
    "            torch.xpu.synchronize()\n",
    "        del model, processor, inputs, generated_ids, generated_ids_trimmed\n",
    "        return output_text[0]\n",
    "    except Exception as e:\n",
    "        print(\"Error generating story: \", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9865e89b-12dd-4f5c-b75d-b32fa427d8f9",
   "metadata": {},
   "source": [
    "## User-provided inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2081e7-7721-409c-91d7-950925156a9d",
   "metadata": {},
   "source": [
    "### Upload image\n",
    "\n",
    "Users could also use sample input images from [sample-inputs](./assets/sample-inputs) folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bfeced2-9cf9-4f5b-8cdd-5d3aae55625c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please upload an image file (e.g., jpg, png, gif).\n",
      "If no image is uploaded, a default image will be attempted from: ./assets/sample-inputs/input1.jpg\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac1e75c0ab1247c5b174c06e9d16c6a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(value=(), accept='image/*', description='Upload')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65a2d06e99a04e379ac82164a2b5fb91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "default_image_path = \"./assets/sample-inputs/input1.jpg\" \n",
    "\n",
    "image = None\n",
    "\n",
    "uploader = widgets.FileUpload(\n",
    "    accept='image/*', \n",
    "    multiple=False    \n",
    ")\n",
    "\n",
    "output_area = widgets.Output()\n",
    "\n",
    "def _load_and_store_pil_image(source_type, data, filename_for_error_msg=None):\n",
    "    \"\"\"\n",
    "    Loads image data into a PIL.Image object and stores it globally.\n",
    "    source_type: 'path' (data is a file path) or 'bytes' (data is image byte content).\n",
    "    Returns PIL.Image object on success, None on failure.\n",
    "    \"\"\"\n",
    "    global image\n",
    "    try:\n",
    "        if source_type == 'path':\n",
    "            pil_img = PILImage.open(data)\n",
    "        elif source_type == 'bytes':\n",
    "            pil_img = PILImage.open(io.BytesIO(data))\n",
    "        else: \n",
    "            image = None\n",
    "            return None \n",
    "        \n",
    "        image = pil_img\n",
    "        return pil_img\n",
    "    except Exception as e:\n",
    "        image = None\n",
    "        print(f\"Error loading image: {e}\")\n",
    "\n",
    "def display_default_image_handler():\n",
    "    \"\"\"Loads the default image as a PIL object, stores it, and displays it.\"\"\"\n",
    "    with output_area:\n",
    "        output_area.clear_output() \n",
    "        if not os.path.exists(default_image_path):\n",
    "            global image\n",
    "            image = None\n",
    "            print(f\"Default image not found: {default_image_path}. Please check the path.\")\n",
    "            return\n",
    "\n",
    "        pil_img = _load_and_store_pil_image('path', default_image_path)\n",
    "        if pil_img:\n",
    "            display(IPImage(filename=default_image_path))\n",
    "            print(f\"Displaying default image: {default_image_path}. Stored as PIL.\")\n",
    "        else:\n",
    "            print(f\"Error loading default PIL image from '{default_image_path}'.\")\n",
    "\n",
    "def on_upload_event_handler(change):\n",
    "    \"\"\"Handles file upload/clear, stores as PIL Image, and displays.\"\"\"\n",
    "    with output_area:\n",
    "        output_area.clear_output()\n",
    "\n",
    "        if not uploader.value: \n",
    "            print(\"No file uploaded. Displaying default image.\")\n",
    "            display_default_image_handler() \n",
    "            return\n",
    "\n",
    "        \n",
    "        uploaded_file_info = uploader.value[0]\n",
    "        file_content_bytes = uploaded_file_info['content']\n",
    "        file_name = uploaded_file_info['name']\n",
    "\n",
    "        pil_img = _load_and_store_pil_image('bytes', file_content_bytes, filename_for_error_msg=file_name)\n",
    "        if pil_img:\n",
    "            display(IPImage(data=file_content_bytes)) \n",
    "            print(f\"Displayed uploaded image: {file_name}. Stored as PIL.\")\n",
    "        else:\n",
    "            print(f\"Error processing uploaded image '{file_name}' into PIL format.\")\n",
    "\n",
    "uploader.observe(on_upload_event_handler, names='value')\n",
    "\n",
    "print(\"Please upload an image file (e.g., jpg, png, gif).\")\n",
    "print(f\"If no image is uploaded, a default image will be attempted from: {default_image_path}\")\n",
    "display(uploader)\n",
    "display(output_area)\n",
    "\n",
    "with output_area:\n",
    "    output_area.clear_output(wait=True) \n",
    "    display_default_image_handler() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0bdf90-c5e6-4b8d-8b8c-38b713a4b3a1",
   "metadata": {},
   "source": [
    "### Select Genre for the story\n",
    "\n",
    "Specify the genre in which user would want the VL Model to generate the story."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fffed399-458c-4a78-9fa3-2fd682bea682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1195d8bf8acd4eeab9e572cc732fae8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RadioButtons(description='Genre', options=('Fantasy', 'Horror', 'Science Fiction', 'Thriller and Suspense', 'R…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Top genres are listed using RadioButtons function from ipywidgets\n",
    "genre = widgets.RadioButtons(\n",
    "    options=['Fantasy', 'Horror', 'Science Fiction', 'Thriller and Suspense', 'Romance', 'Historical fiction'],\n",
    "    value='Fantasy', # Default'\n",
    "    description='Genre',\n",
    "    disabled=False\n",
    ")\n",
    "display(genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5a01472-e0c5-40b3-85b1-8528ba1b5f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.xpu.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df796997-6d5e-479d-8bbb-0f4fdd934363",
   "metadata": {},
   "source": [
    "## Story Generation\n",
    "\n",
    "This orchestrates the story generation by taking an image and a user-defined genre as input and then producing a narrative aligned with the chosen genre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebedabc8-cbe7-4ea9-8f0c-6a2796c383da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Science Fiction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6f17d6cac4c42fdb66afed2d53efb16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the vast wilderness of the American West, under a clear blue sky dotted with wispy clouds, stood an ancient white stallion named Luna. Luna was no ordinary horse; he belonged to a special breed known as the Freedom Runners, created by a secretive organization dedicated to preserving endangered equine species. Luna's coat shimmered in the sun, and his mane flowed like a waterfall.\n",
      "\n",
      "Near Luna sat a peculiar looking dog, sleek with a golden coat and expressive green eyes. This dog was named Shadow, a modern mutt who had been specially trained by the organization to accompany Luna during his daily patrols. Shadow had once belonged to one of the founder's children, but tragedy had separated him from the family years ago. He now lived with the Freedom Runners as part of their conservation efforts.\n",
      "\n",
      "Their world was one of harmony and balance, where humans, animals, and nature coexisted peacefully, respecting each other's roles within the ecosystem. The organization was a secret, dedicated group working behind the scenes to protect the natural world and its inhabitants from encroaching human interests.\n",
      "\n",
      "One day, a strange entity began to appear in their realm. It resembled an organic cloud, able to grow and shrink to the size of a human child. Initially, it presented itself as benign, bringing warmth and a sense of belonging to those around it. However, as it became more complex, the entity started to disrupt the equilibrium of the ecosystem. Plants began to wilt, animals exhibited unnatural behaviors, and the climate seemed to change.\n",
      "\n",
      "The organization's members were initially oblivious to the threat until they realized something wasn't right. They knew the entity appeared out of nowhere, and it demanded that the world submit to its will. They suspected it might have been created by another, even more powerful entity who saw the world's beauty as a resource to be exploited rather than respected.\n",
      "\n",
      "The leadership of the organization then decided to take drastic measures. They sent Luna and Shadow on a perilous mission to confront the entity. Luna, a veteran of many travels and battles against the elements, was not afraid to face the unknown. His heart, however, held something he couldn't explain—a feeling that spoke to him even though he lacked words for it.\n",
      "\n",
      "Shadow, on the other hand, felt a sense of relief knowing his mission was about to begin. He could see danger approaching and understood the gravity of his role. Together, they embarked on a journey, guided by an inner compass that pointed towards the entity's origin.\n",
      "\n",
      "The chase was long and perilous. Luna's instincts told them to avoid urban areas, knowing that the entity was likely to materialize in places where humans were too numerous. The landscape they traversed was harsh, with rugged terrain and unpredictable weather. Yet, they pressed on, driven by a newfound determination to stop the entity.\n",
      "\n",
      "Finally, they reached the source of the entity—a ancient, forgotten temple hidden deep in the heart of the forest. Inside, they found rituals of sorts carried out by an old, almost forgotten tribe who believed the entity was a bringer of power.\n",
      "\n",
      "Luna and Shadow were confronted by two figures from the tribe, one tall and stoic, the other small and timid. The tall figure explained that the entity was born to unite all living things into one harmony, but it was being corrupted by humans' greed and arrogance. The timid figure admitted that she had been manipulated by the entity, but her actions had only served to strengthen it.\n",
      "\n",
      "The conversation made Luna realize that the entity's true nature wasn't evil but misunderstood and misaligned intentions. Shadow, on the other hand, felt a connection to the entity's power, a pull that seemed to say, \"We need you.\"\n",
      "\n",
      "Their final choice was to destroy the entity or allow it to control the world. Luna and Shadow decided to destroy it, believing that would save the ecosystem from destruction and restore balance. They took on the entity, using Luna's strength and Shadow's intelligence to outsmart it.\n",
      "\n",
      "As they defeated the entity, a light emerged from it, signifying its passing form. The old tribe watched in awe, recognizing the difference between the entity in its former guise and the awakened spirit it became.\n",
      "\n",
      "With the entity gone, the ecosystem began to heal. Plants grew lush again, animals resumed their natural behavior, and the climate stabilized. The organization celebrated their victory, but they knew the journey had taken a profound impact on their lives.\n",
      "\n",
      "From then on, Luna and Shadow patrolled the land together, no longer just companions, but protectors of the environment and the creatures it housed. Shadow returned home, finding the family he had left behind was now thriving under their care. Luna remained, always ready to face whatever new challenges the wild west might bring.\n",
      "\n",
      "This story underscores the importance of harmony between humans and nature and highlights the value of understanding one another, even when they come from vastly different backgrounds and understandings of the world.\n"
     ]
    }
   ],
   "source": [
    "print(genre.value)\n",
    "story = story_generation(image, genre.value)\n",
    "print(story)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb84096-58e5-44d8-906e-33f2ebbccdbb",
   "metadata": {},
   "source": [
    "## Sample Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974a44cb-5c26-485c-b500-b354618ef02d",
   "metadata": {},
   "source": [
    "### Fantasy Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e692e23-667d-47e7-a337-454b5cf074ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(genre.value)\n",
    "story = story_generation(image, genre.value)\n",
    "print(story)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c3dbf9-bf4b-49ae-8285-b8458c06a5bd",
   "metadata": {},
   "source": [
    "### Science Fiction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fbd20e-9d46-4375-bb49-e646b6771868",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(genre.value)\n",
    "story = story_generation(image, genre.value)\n",
    "print(story)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
