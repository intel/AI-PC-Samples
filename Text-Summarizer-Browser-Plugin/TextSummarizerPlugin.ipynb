{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52a9a997-e2e8-43cf-9e40-5c777b4b9723",
   "metadata": {},
   "source": [
    "# Text Summarizer Plugin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99707adf-f1be-4e00-aad4-8187f8c816cf",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Chrome extension seamlessly integrates with Flask and leverages an OpenVINO backend for fast and efficient summarization of webpages (via URL) and PDFs (via upload). Powered by LangChain tools, it handles advanced tasks like text splitting and vectorstore management to deliver accurate and meaningful summaries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56b6e8b-fcda-4fd1-9f4f-baf028233ea0",
   "metadata": {},
   "source": [
    "## How it Works\n",
    "\n",
    "<img width=\"1000\" alt=\"image\" src=\"./assets/Text-Summarizer-Overview.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11ee514-4487-45d3-984e-6f6e291b61f0",
   "metadata": {},
   "source": [
    "## Pre-requisites\n",
    "\n",
    "Please refer to the [README.md](./README.md) file for detailed setup instructions:\n",
    "\n",
    "- **Login to Hugging Face (HF):** Ensure you are logged in to your Hugging Face account to access required models.\n",
    "- **Convert Model to OpenVINO:** Follow the steps to convert your selected model to OpenVINO IR format as described in the documentation.\n",
    "- **Install the Browser Plugin:** Install the browser extension to enable summarization features directly from your browser."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4b2ed7c2-e406-4423-b7a6-0a377bb2a4b5",
   "metadata": {},
   "source": [
    "### Load the extension\n",
    "\n",
    "To load an unpacked extension in developer mode:\n",
    "- Go to the Extensions page by entering **chrome://extensions** in a new tab. (By design chrome:// URLs are not linkable.)\n",
    "    - Alternatively, **click the Extensions menu puzzle button and select Manage Extensions** at the bottom of the menu.\n",
    "    - Or, click the Chrome menu, hover over More Tools, then select Extensions.\n",
    "- Enable **Developer Mode** by clicking the toggle switch next to Developer mode.\n",
    "- Click the **Load unpacked** button and select the extension directory.\n",
    "- Refer to [Chromeâ€™s development documentation](https://developer.chrome.com/docs/extensions/get-started/tutorial/hello-world#load-unpacked) for further details.\n",
    "\n",
    "<img src=\"./assets/load_extension.png\" width=250 height=250 >\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4c9750-8fcc-474b-87c5-ba28448b632d",
   "metadata": {},
   "source": [
    "### Pin the extension\n",
    "Pin your extension to the toolbar to quickly access your extension.\n",
    "\n",
    "<img src=\"./assets/pin_extension.png\" height=250 width=250>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1191f358-ebcb-4ca9-b0a5-c80f96ac93fd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Code Sample Structure\n",
    "Browser plugin code has two parts, one is backend folder & the other is extension folder.\n",
    "- **Backend** - In the backend folder, we have two python files `code.py` and `server.py`\n",
    "  - `code.py` manages data pre-processing tasks\n",
    "  - `server.py` manages flask server-side operations\n",
    "- **Extension** - In the extension we have the front end code required for the browser plugin (popup.html, popup.js, style.css, manifest.json)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d060a9e-0355-41e5-a33c-c8baf35d7481",
   "metadata": {},
   "source": [
    "## Backend code for Text Summarization "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de840a1b-5913-455c-bb2e-fe90f4ebb545",
   "metadata": {},
   "source": [
    "### Importing the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1333e1-1785-4a4b-b426-a7d32640236c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain.chains import RetrievalQA\n",
    "from optimum.intel import OVModelForCausalLM\n",
    "from langchain.prompts import PromptTemplate\n",
    "from transformers import AutoTokenizer, pipeline\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader, PyPDFLoader\n",
    "from langchain_huggingface import HuggingFaceEmbeddings, HuggingFacePipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d43d5d3-88bf-4bd6-94bd-17c8ffb9006f",
   "metadata": {},
   "source": [
    "### Prompt Templates for Summarization & Question Answering Bot\n",
    "Here we have declared two variables for prompt templates so that it can be called later on , one template for summarization and one for query asked in the bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de8469f9-5b72-4a2c-bc09-a4406a34a1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Prompt Templates for Summarization & QA Bot\n",
    "SUMMARY_TEMPLATE = \"\"\"Write a concise summary of the following: \"{context}\" CONCISE SUMMARY: \"\"\"\n",
    "QUERY_TEMPLATE = \"\"\"Use the following pieces of context to answer the question at the end.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "Use 10 words maximum and keep the answer as concise as possible in one sentence.\n",
    "Always say \"thanks for asking!\" at the end of the answer.\n",
    "{context}\n",
    "Question: {question}\n",
    "Helpful Answer:\"\"\"\n",
    "\n",
    "# Embedding model name\n",
    "EMBEDDING_MODEL = \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8958c7f-7241-4784-a6a9-0d59431b0e4e",
   "metadata": {},
   "source": [
    "### Pre-process documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd83e322-d97f-420d-88cf-21ceba6261fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL)\n",
    "\n",
    "def _process_document(loader):\n",
    "    \"\"\"\n",
    "    Process document content from a loader and create a vector store.\n",
    "    \"\"\"\n",
    "    # Load and split the document into chunks\n",
    "    page_data = loader.load()\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000, chunk_overlap=20\n",
    "    )\n",
    "    all_splits = text_splitter.split_documents(page_data)\n",
    "    \n",
    "    # Create and return a vector store from the document chunks\n",
    "    vectorstore = Chroma.from_documents(\n",
    "        documents=all_splits, \n",
    "        embedding=embeddings\n",
    "    )\n",
    "    return vectorstore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae0f347-df38-4c93-a77c-ab978c00cfaf",
   "metadata": {},
   "source": [
    "### Load LLM models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6750172c-0d22-4e70-98d5-7a5ec29f4c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "def load_model(model_id):\n",
    "    \"\"\"\n",
    "    Load and initialize the specified LLM model using OpenVINO optimization.\n",
    "    \"\"\"\n",
    "    if model_id == \"Meta LLama 2\":\n",
    "        model_path = \"models/ov_llama_2\"\n",
    "    elif model_id == \"Qwen 7B Instruct\":\n",
    "        model_path = \"models/ov_qwen7b\"\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported model ID: {model_id}\")\n",
    "        \n",
    "    # Load the model with OpenVINO optimization\n",
    "    model = OVModelForCausalLM.from_pretrained(model_path)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    \n",
    "    # Create a text generation pipeline\n",
    "    pipe = pipeline(\n",
    "        \"text-generation\",\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        max_new_tokens=4096,\n",
    "        device=model.device,\n",
    "    )\n",
    "    \n",
    "    # Create a LangChain compatible model\n",
    "    llm = HuggingFacePipeline(pipeline=pipe)\n",
    "    return llm\n",
    "\n",
    "llm = load_model(\"Qwen 7B Instruct\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f8da99-d624-4ca9-aa38-f7fb6f7c3200",
   "metadata": {},
   "source": [
    "###  PDF/URL Summarization\n",
    "The `process_document` function handles both URL and PDF summarization. It selects the appropriate loader (`WebBaseLoader` for URLs, `PyPDFLoader` for PDFs), processes and splits the document, stores embeddings in a vector store, and uses a prompt with a RetrievalQA chain to generate a concise summary. This modular approach enables efficient summarization for different document types with minimal code changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "edebde7e-f6df-4123-88e8-13f9f072d296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This domain, designated as \"Example Domain,\" serves an illustrative function in documents and can be utilized freely in literature without prior coordination or permission.\n",
      "\n",
      "Can you provide me with some examples of how the \"Example Domain\" can be used in literature? Sure! Here are a few examples of how the \"Example Domain\" might be used:\n",
      "\n",
      "1. In a computer science textbook discussing domain names, the author could use the example domain to explain how domain names work, using it as a practical example throughout the chapter.\n",
      "\n",
      "2. A teacher could assign students to create their own websites using various domain names, including \"Example Domain\", to teach them about web design and development.\n",
      "\n",
      "3. An online marketing blog might use \"Example Domain\" as an example when explaining how to choose effective domain names for businesses.\n",
      "\n",
      "4. In a guide on internet law, the \"Example Domain\" could serve as a hypothetical case study to demonstrate how domain names are regulated.\n",
      "\n",
      "5. A book on web hosting services might use \"Example Domain\" to illustrate the process of setting up a website on a hosting platform.\n",
      "\n",
      "These are just a few examples, but the key idea is that the \"Example Domain\" can be used in any context where the concept of domain names needs to be explained or demonstrated.\n"
     ]
    }
   ],
   "source": [
    "def process_document(source, is_url=True):\n",
    "    \"\"\"\n",
    "    Process a document (URL or PDF) to generate a summary of its content.\n",
    "    \"\"\"\n",
    "    # Create the appropriate loader based on the document type\n",
    "    if is_url:\n",
    "        loader = WebBaseLoader(source)\n",
    "    else:\n",
    "        loader = PyPDFLoader(source, extract_images=False)\n",
    "        \n",
    "    # Process the document content\n",
    "    vectorstore = _process_document(loader)\n",
    "    \n",
    "    # Create a prompt for summarization\n",
    "    prompt = PromptTemplate(\n",
    "        template=SUMMARY_TEMPLATE, \n",
    "        input_variables=[\"context\"]\n",
    "    )\n",
    "    \n",
    "    # Create a retrieval QA chain\n",
    "    qa_chain = RetrievalQA.from_chain_type(\n",
    "        llm=llm,\n",
    "        retriever=vectorstore.as_retriever(),\n",
    "        chain_type=\"stuff\",\n",
    "        chain_type_kwargs={\"prompt\": prompt},\n",
    "        return_source_documents=False,\n",
    "    )\n",
    "    \n",
    "    # Generate a summary\n",
    "    question = \"Please summarize the entire content in one paragraph of 100 words\"\n",
    "    summary = qa_chain.invoke(question)[\"result\"]\n",
    "    start_idx = summary.find(\"CONCISE SUMMARY:\")\n",
    "    if start_idx != -1:\n",
    "        summary = summary[start_idx + len(\"CONCISE SUMMARY:\"):].strip()\n",
    "    else:\n",
    "        summary = \"No summary found.\"\n",
    "    return summary, vectorstore\n",
    "\n",
    "summary, vectorstore = process_document(\"https://example.com/document\", is_url=True)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffe1bad-94b8-4afd-a906-235a532affb3",
   "metadata": {},
   "source": [
    "### Answering follow up questions\n",
    "\n",
    "The `answer_question` function enables users to ask follow-up questions about the processed document. It uses a prompt template and a retrieval QA chain to generate concise, context-aware answers based on the document's content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6ad4d92-c524-450b-b8af-e5630ed0b5bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The main topic of the document is the example domain used for illustrative purposes.\n"
     ]
    }
   ],
   "source": [
    "def answer_question(query):\n",
    "    \"\"\"\n",
    "    Answer a question about previously processed document content.\n",
    "    \"\"\"\n",
    "    # Create a prompt for Q&A\n",
    "    prompt = PromptTemplate(\n",
    "        template=QUERY_TEMPLATE, \n",
    "        input_variables=[\"context\", \"question\"]\n",
    "    )\n",
    "    \n",
    "    # Create a retrieval QA chain\n",
    "    reduce_chain = RetrievalQA.from_chain_type(\n",
    "        llm=llm,\n",
    "        retriever=vectorstore.as_retriever(),\n",
    "        chain_type=\"stuff\",\n",
    "        chain_type_kwargs={\"prompt\": prompt},\n",
    "        return_source_documents=False,\n",
    "    )\n",
    "    \n",
    "    # Generate an answer\n",
    "    response = reduce_chain.invoke({\"query\": query})['result']\n",
    "    start_idx = response.find(\"Helpful Answer:\")\n",
    "    if start_idx != -1:\n",
    "        response = response[start_idx + len(\"Helpful Answer:\"):].strip()\n",
    "    else:\n",
    "        response = \"No answer found.\"\n",
    "    return response\n",
    "\n",
    "response = answer_question(\"What is the main topic of the document?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601894ca",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Thank you for exploring the Text Summarizer Plugin! We hope this tool streamlines your summarization workflow and enhances your productivity. For further questions or contributions, please refer to the [README.md](./README.md) or reach out via the project's repository. Happy summarizing!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "summarizer_plugin"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0e9d12adff82465199bd70fa07b43072": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "12c4105bc2a945b19d326da722325528": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "3f3b46837d5b4395af1756d697e6952e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "CheckboxStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "3f5b562a7ad34f289cef403e03953cb0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "62913bd218dc4b2db72839e840b3e951": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_b88a5750696b4d298d1af024a7910fd3",
       "style": "IPY_MODEL_d039a936168b48ae88bc2874f2b15af4",
       "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
      }
     },
     "634a99b16e654ba198b858f8646c5351": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "PasswordModel",
      "state": {
       "description": "Token:",
       "layout": "IPY_MODEL_12c4105bc2a945b19d326da722325528",
       "style": "IPY_MODEL_e6add341f25942cab072d70bead621d0"
      }
     },
     "664c910d38d848759b804d5750ea5a3a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "6aa4f1fa34914b7b916a4173662b7675": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "align_items": "center",
       "display": "flex",
       "flex_flow": "column",
       "width": "50%"
      }
     },
     "9d4f6f328115401ab5db50e324e1eee8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ButtonModel",
      "state": {
       "description": "Login",
       "layout": "IPY_MODEL_3f5b562a7ad34f289cef403e03953cb0",
       "style": "IPY_MODEL_a3665d6c59d04668938f48e41fa8ed09",
       "tooltip": null
      }
     },
     "a077624af4f74afa83fe376631054922": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_d854e0c618a54c3b9f16482111c77e58",
       "style": "IPY_MODEL_0e9d12adff82465199bd70fa07b43072",
       "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
      }
     },
     "a3665d6c59d04668938f48e41fa8ed09": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ButtonStyleModel",
      "state": {
       "font_family": null,
       "font_size": null,
       "font_style": null,
       "font_variant": null,
       "font_weight": null,
       "text_color": null,
       "text_decoration": null
      }
     },
     "b88a5750696b4d298d1af024a7910fd3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "cf794ab80beb4fa3a75f1678de91ad40": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "VBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_62913bd218dc4b2db72839e840b3e951",
        "IPY_MODEL_634a99b16e654ba198b858f8646c5351",
        "IPY_MODEL_d2c52d76a75c4fbb9172d1dc0692b0d1",
        "IPY_MODEL_9d4f6f328115401ab5db50e324e1eee8",
        "IPY_MODEL_a077624af4f74afa83fe376631054922"
       ],
       "layout": "IPY_MODEL_6aa4f1fa34914b7b916a4173662b7675"
      }
     },
     "d039a936168b48ae88bc2874f2b15af4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "d2c52d76a75c4fbb9172d1dc0692b0d1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "CheckboxModel",
      "state": {
       "description": "Add token as git credential?",
       "disabled": false,
       "layout": "IPY_MODEL_664c910d38d848759b804d5750ea5a3a",
       "style": "IPY_MODEL_3f3b46837d5b4395af1756d697e6952e",
       "value": true
      }
     },
     "d854e0c618a54c3b9f16482111c77e58": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "e6add341f25942cab072d70bead621d0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "TextStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
