import time
from threading import Thread
import streamlit as st
from llama_cpp import Llama
from llama_cpp.llama_chat_format import MoondreamChatHandler
import tempfile
from PIL import Image
import base64

# Create a Streamlit app that displays the response word by word
st.header("Visual-language assistant with SYCL üêª‚Äç‚ùÑÔ∏è")

# Dropdown to select a model
selected_model = st.selectbox(
    "Please select a model",
    ("vikhyatk/moondream2",
     "microsoft/Phi-3-vision-128k-instruct",
     "Intel/llava-gemma-2b"),
    index=0)

# File uploader for image
img_file_buffer = st.file_uploader(
    'Upload a PNG image', type=[
        "jpg", "png", "gif"])

# Input for image URL
url = st.text_input(
    "Enter the URL of the Image:",
    value="Enter the URL of the Image",
    key="url_path")

# Display the uploaded image or the image from the URL
if img_file_buffer is not None:
    try:
        image = Image.open(img_file_buffer)
        # Manually Adjust the width of the image as per requirement
        st.image(image, width=600)
    except Exception as e:
        st.error(f"Error loading image: {e}")
else:
    st.error("Please provide an image URL or upload an image.")

# Input prompt for the question
question = st.text_input(
    "Enter the question:",
    value="What's the content of the image?",
    key="question")


def getfinalresponse(input_text):
    """ Generate a response based on the input text and image.

    Args:
        input_text (str): The input text or question from the user.

    Yields:
        str: The generated response content word by word. """

    try:
        # Create a temporary file if an image is uploaded
        if img_file_buffer is not None:
            with tempfile.NamedTemporaryFile(delete=False) as tmp_file:
                tmp_file.write(img_file_buffer.getvalue())
                file_path = tmp_file.name

            def image_to_base64_data_uri():
                """
                Convert the uploaded image to a base64 data URI.

                Returns:
                    str: The base64 data URI of the image.
                """
                with open(file_path, "rb") as img_file:
                    base64_data = base64.b64encode(
                        img_file.read()).decode('utf-8')
                    return f"data:image/jpg;base64,{base64_data}"

        # Initialize the chat handler with a pre-trained model
        chat_handler = MoondreamChatHandler.from_pretrained(
            repo_id="vikhyatk/moondream2",
            filename="*mmproj*",
        )

        # Initialize the Llama model with the pre-trained model and chat
        # handler
        llm = Llama.from_pretrained(
            repo_id=selected_model,
            filename="*text-model*",
            chat_handler=chat_handler,
            n_gpu_layers=-1,  # Uncomment to use GPU acceleration
            seed=1337,  # Uncomment to set a specific seed
            n_ctx=2048,  # Uncomment to increase the context window
            n_threads=16,
        )

        # Create a chat completion request with the appropriate image URL
        if img_file_buffer is not None:
            response = llm.create_chat_completion(
                messages=[
                    {
                        "role": "user",
                        "content": [
                            {"type": "text", "text": question},
                            {"type": "image_url", "image_url": {"url": image_to_base64_data_uri()}}
                        ]
                    }
                ],
                stream=True
            )
        else:
            response = llm.create_chat_completion(
                messages=[
                    {
                        "role": "user",
                        "content": [
                            {"type": "text", "text": question},
                            {"type": "image_url", "image_url": {"url": url}}
                        ]
                    }
                ],
                stream=True
            )

        # Stream and yield the response content word by word
        for chunk in response:
            res = chunk['choices'][0]['delta']
            if 'content' in res:
                word = res['content'].split()
                for token in word:
                    yield token + " "
    except Exception as e:
        st.error(f"An error occurred: {e}")


# Generate response when the button is clicked
if st.button("Generate"):
    with st.spinner("Running....üêé"):
        if not question.strip():
            st.error("Please enter a question.")
        elif not url.strip() and img_file_buffer is None:
            st.error("Please provide an image URL or upload an image.")
        else:
            st.write_stream(getfinalresponse(question))
